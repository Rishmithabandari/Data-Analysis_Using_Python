{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy import stats\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "data = pd.read_csv('/content/diabetes_data_upload.csv')\n",
        "\n",
        "\n",
        "X = data.drop(columns=['class'])\n",
        "y = data['class'].map({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'Confusion Matrix': confusion_matrix(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name}:\")\n",
        "    print(f\"  Accuracy: {metrics['Accuracy']:.2f}\")\n",
        "    print(f\"  Precision: {metrics['Precision']:.2f}\")\n",
        "    print(f\"  Recall: {metrics['Recall']:.2f}\")\n",
        "    print(f\"  Confusion Matrix:\\n{metrics['Confusion Matrix']}\\n\")\n",
        "\n",
        "for model_name, metrics in results.items():\n",
        "    tn, fp, fn, tp = metrics['Confusion Matrix'].ravel()\n",
        "    type_ii_error_rate = fn / (fn + tp)\n",
        "    print(f\"{model_name} Type II Error Rate: {type_ii_error_rate:.2f}\")\n",
        "\n",
        "correctly_classified = data[data['class'] == 'Positive']\n",
        "misclassified = data[data['class'] == 'Negative']\n",
        "\n",
        "mean_age_correct = correctly_classified['Age'].mean()\n",
        "mean_age_misclassified = misclassified['Age'].mean()\n",
        "\n",
        "z_stat, p_value = stats.ttest_ind(correctly_classified['Age'], misclassified['Age'], equal_var=False)\n",
        "print(f\"Z-Test: Z-statistic = {z_stat:.2f}, p-value = {p_value:.4f}\")\n",
        "\n",
        "# Random Forest analysis for Type I error\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
        "type_i_error_rate = fp / (fp + tn)\n",
        "print(f\"Random Forest Type I Error Rate: {type_i_error_rate:.2f}\")\n",
        "\n",
        "if type_i_error_rate > 0.20:\n",
        "    z_stat_i, p_value_i = stats.ztest([type_i_error_rate], value=0.20)\n",
        "    print(f\"One-Sample Z-Test for Type I Error: Z-statistic = {z_stat_i:.2f}, p-value = {p_value_i:.4f}\")\n",
        "\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    type_ii_error_rate = fn / (fn + tp)\n",
        "    print(f\"{model_name} Type II Error Rate: {type_ii_error_rate:.2f}\")\n",
        "\n",
        "logistic_fn = confusion_matrix(y_test, models['Logistic Regression'].predict(X_test)).ravel()[2]\n",
        "rf_fn = confusion_matrix(y_test, models['Random Forest'].predict(X_test)).ravel()[2]\n",
        "\n",
        "z_stat_fn, p_value_fn = stats.ttest_ind([logistic_fn], [rf_fn], equal_var=False)\n",
        "print(f\"Z-Test for Type II Error Rates: Z-statistic = {z_stat_fn:.2f}, p-value = {p_value_fn:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LRd-pHAbKFa",
        "outputId": "bf70b9cf-eedd-42a1-b582-b60f02f9ae5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "  Accuracy: 0.92\n",
            "  Precision: 0.93\n",
            "  Recall: 0.96\n",
            "  Confusion Matrix:\n",
            "[[28  5]\n",
            " [ 3 68]]\n",
            "\n",
            "Decision Tree:\n",
            "  Accuracy: 0.95\n",
            "  Precision: 1.00\n",
            "  Recall: 0.93\n",
            "  Confusion Matrix:\n",
            "[[33  0]\n",
            " [ 5 66]]\n",
            "\n",
            "Random Forest:\n",
            "  Accuracy: 0.99\n",
            "  Precision: 1.00\n",
            "  Recall: 0.99\n",
            "  Confusion Matrix:\n",
            "[[33  0]\n",
            " [ 1 70]]\n",
            "\n",
            "Gradient Boosting:\n",
            "  Accuracy: 0.97\n",
            "  Precision: 1.00\n",
            "  Recall: 0.96\n",
            "  Confusion Matrix:\n",
            "[[33  0]\n",
            " [ 3 68]]\n",
            "\n",
            "Logistic Regression Type II Error Rate: 0.04\n",
            "Decision Tree Type II Error Rate: 0.07\n",
            "Random Forest Type II Error Rate: 0.01\n",
            "Gradient Boosting Type II Error Rate: 0.04\n",
            "Z-Test: Z-statistic = 2.49, p-value = 0.0132\n",
            "Random Forest Type I Error Rate: 0.00\n",
            "Logistic Regression Type II Error Rate: 0.04\n",
            "Decision Tree Type II Error Rate: 0.07\n",
            "Random Forest Type II Error Rate: 0.01\n",
            "Gradient Boosting Type II Error Rate: 0.04\n",
            "Z-Test for Type II Error Rates: Z-statistic = nan, p-value = nan\n"
          ]
        }
      ]
    }
  ]
}